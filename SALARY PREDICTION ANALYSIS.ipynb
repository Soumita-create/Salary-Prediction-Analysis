{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eb5f2a7",
   "metadata": {},
   "source": [
    "# EXPLORATORY DATA ANALYSIS (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01ae5868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  FIRST NAME   LAST NAME SEX         DOJ CURRENT DATE DESIGNATION   AGE  \\\n",
      "0     TOMASA       ARMEN   F   5-18-2014   01-07-2016     Analyst  21.0   \n",
      "1      ANNIE         NaN   F         NaN   01-07-2016   Associate   NaN   \n",
      "2      OLIVE        ANCY   F   7-28-2014   01-07-2016     Analyst  21.0   \n",
      "3     CHERRY     AQUILAR   F  04-03-2013   01-07-2016     Analyst  22.0   \n",
      "4       LEON  ABOULAHOUD   M  11-20-2014   01-07-2016     Analyst   NaN   \n",
      "\n",
      "   SALARY        UNIT  LEAVES USED  LEAVES REMAINING  RATINGS  PAST EXP  \n",
      "0   44570     Finance         24.0               6.0      2.0         0  \n",
      "1   89207         Web          NaN              13.0      NaN         7  \n",
      "2   40955     Finance         23.0               7.0      3.0         0  \n",
      "3   45550          IT         22.0               8.0      3.0         0  \n",
      "4   43161  Operations         27.0               3.0      NaN         3  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2639 entries, 0 to 2638\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   FIRST NAME        2639 non-null   object \n",
      " 1   LAST NAME         2637 non-null   object \n",
      " 2   SEX               2639 non-null   object \n",
      " 3   DOJ               2638 non-null   object \n",
      " 4   CURRENT DATE      2639 non-null   object \n",
      " 5   DESIGNATION       2639 non-null   object \n",
      " 6   AGE               2636 non-null   float64\n",
      " 7   SALARY            2639 non-null   int64  \n",
      " 8   UNIT              2639 non-null   object \n",
      " 9   LEAVES USED       2636 non-null   float64\n",
      " 10  LEAVES REMAINING  2637 non-null   float64\n",
      " 11  RATINGS           2637 non-null   float64\n",
      " 12  PAST EXP          2639 non-null   int64  \n",
      "dtypes: float64(4), int64(2), object(7)\n",
      "memory usage: 268.2+ KB\n",
      "None\n",
      "               AGE         SALARY  LEAVES USED  LEAVES REMAINING      RATINGS  \\\n",
      "count  2636.000000    2639.000000  2636.000000       2637.000000  2637.000000   \n",
      "mean     24.756449   58136.678287    22.501517          7.503223     3.486159   \n",
      "std       3.908228   36876.956944     4.604469          4.603193     1.114933   \n",
      "min      21.000000   40001.000000    15.000000          0.000000     2.000000   \n",
      "25%      22.000000   43418.000000    19.000000          4.000000     2.000000   \n",
      "50%      24.000000   46781.000000    22.000000          8.000000     3.000000   \n",
      "75%      25.000000   51401.500000    26.000000         11.000000     4.000000   \n",
      "max      45.000000  388112.000000    30.000000         15.000000     5.000000   \n",
      "\n",
      "          PAST EXP  \n",
      "count  2639.000000  \n",
      "mean      1.566881  \n",
      "std       2.728416  \n",
      "min       0.000000  \n",
      "25%       0.000000  \n",
      "50%       1.000000  \n",
      "75%       2.000000  \n",
      "max      23.000000  \n",
      "FIRST NAME          0\n",
      "LAST NAME           2\n",
      "SEX                 0\n",
      "DOJ                 1\n",
      "CURRENT DATE        0\n",
      "DESIGNATION         0\n",
      "AGE                 3\n",
      "SALARY              0\n",
      "UNIT                0\n",
      "LEAVES USED         3\n",
      "LEAVES REMAINING    2\n",
      "RATINGS             2\n",
      "PAST EXP            0\n",
      "dtype: int64\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Salary'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Salary'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(data\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum())\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Visualize the distribution of the target variable (assuming it's 'Salary')\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m sns\u001b[38;5;241m.\u001b[39mhistplot(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSalary\u001b[39m\u001b[38;5;124m'\u001b[39m], kde\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     23\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistribution of Salary\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     24\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSalary\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Salary'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'Salary Prediction of Data Professions.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(data.info())\n",
    "\n",
    "# Display summary statistics\n",
    "print(data.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Visualize the distribution of the target variable (assuming it's 'Salary')\n",
    "sns.histplot(data['Salary'], kde=True)\n",
    "plt.title('Distribution of Salary')\n",
    "plt.xlabel('Salary')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Visualize relationships between features (assuming some common features)\n",
    "sns.pairplot(data)\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(data.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4b7c6e",
   "metadata": {},
   "source": [
    "# FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56475115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = pd.DataFrame({\n",
    "    'Experience': [1, 6, 12, 4, 9],\n",
    "    'Education Level': ['Bachelor', 'Master', 'PhD', 'Associate', 'Bachelor']\n",
    "})\n",
    "\n",
    "# Feature engineering to create 'Experience_Level' column\n",
    "data['Experience_Level'] = data['Experience'].apply(lambda x: 'Senior' if x > 10 else 'Mid' if x > 5 else 'Junior')\n",
    "\n",
    "# Display the first few rows to verify the new feature\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec2260e",
   "metadata": {},
   "source": [
    "# DATA PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b594a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Sample data\n",
    "data = pd.DataFrame({\n",
    "    'Experience': [1, 6, 12, 4, 9],\n",
    "    'Age': [23, 45, 34, 22, 28],\n",
    "    'Job Title': ['Engineer', 'Manager', 'Director', 'Intern', 'Engineer'],\n",
    "    'Education Level': ['Bachelor', 'Master', 'PhD', 'Associate', 'Bachelor']\n",
    "})\n",
    "\n",
    "# Define numerical and categorical features\n",
    "numerical_features = ['Experience', 'Age']\n",
    "categorical_features = ['Job Title', 'Education Level']\n",
    "\n",
    "# Define preprocessing steps\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Apply preprocessing\n",
    "preprocessed_data = preprocessor.fit_transform(data)\n",
    "\n",
    "# Extract numerical and one-hot encoded data separately\n",
    "numerical_data = preprocessed_data[:, :len(numerical_features)]\n",
    "categorical_data = preprocessed_data[:, len(numerical_features):]\n",
    "\n",
    "# Create DataFrame with appropriate column names\n",
    "column_names = numerical_features + list(preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_features))\n",
    "preprocessed_df = pd.DataFrame(data=np.hstack((numerical_data, categorical_data)), columns=column_names)\n",
    "\n",
    "print(preprocessed_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5bbe36",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING AND MODEL DEVELOPEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0017383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'Salary Prediction of Data Professions.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(data.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Print column names to verify the target variable name\n",
    "print(\"\\nColumn names:\")\n",
    "print(data.columns)\n",
    "\n",
    "# Strip leading/trailing whitespaces from column names\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Reprint column names to verify stripping worked\n",
    "print(\"\\nColumn names after stripping:\")\n",
    "print(data.columns)\n",
    "\n",
    "# Assuming 'salary' is the target variable, adjust this if the column name is different\n",
    "target_variable = 'salary'\n",
    "\n",
    "# Verify the exact target column name\n",
    "target_variable = [col for col in data.columns if 'salary' in col.lower()][0]\n",
    "print(f\"\\nTarget variable name: {target_variable}\")\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(target_variable, axis=1)\n",
    "y = data[target_variable]\n",
    "\n",
    "# Preprocessing for numerical and categorical features\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the model pipeline\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R^2 Score: {r2}\")\n",
    "\n",
    "# Hyperparameter tuning (optional)\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [50, 100, 200],\n",
    "    'regressor__max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'regressor__max_depth': [None, 10, 20, 30]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='r2')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_}\")\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "mse_best = mean_squared_error(y_test, y_pred_best)\n",
    "r2_best = r2_score(y_test, y_pred_best)\n",
    "\n",
    "print(f\"Mean Squared Error (Best Model): {mse_best}\")\n",
    "print(f\"R^2 Score (Best Model): {r2_best}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f133ed",
   "metadata": {},
   "source": [
    "# MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93893adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'Salary Prediction of Data Professions.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(data.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Print column names to verify the target variable name\n",
    "print(\"\\nColumn names:\")\n",
    "print(data.columns)\n",
    "\n",
    "# Strip leading/trailing whitespaces from column names\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Verify the exact target column name\n",
    "target_variable = [col for col in data.columns if 'salary' in col.lower()][0]\n",
    "print(f\"\\nTarget variable name: {target_variable}\")\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop(target_variable, axis=1)\n",
    "y = data[target_variable]\n",
    "\n",
    "# Preprocessing for numerical and categorical features\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the model pipeline\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"R^2 Score: {r2}\")\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.3)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Actual vs Predicted Salaries')\n",
    "plt.show()\n",
    "\n",
    "# Residuals plot\n",
    "residuals = y_test - y_pred\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(residuals, kde=True, bins=30)\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Residuals Distribution')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_pred, residuals, alpha=0.3)\n",
    "plt.axhline(0, color='r', linestyle='--', linewidth=2)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Predicted vs Residuals')\n",
    "plt.show()\n",
    "\n",
    "# Hyperparameter tuning (optional)\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [50, 100, 200],\n",
    "    'regressor__max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'regressor__max_depth': [None, 10, 20, 30]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='r2')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_}\")\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "mse_best = mean_squared_error(y_test, y_pred_best)\n",
    "rmse_best = np.sqrt(mse_best)\n",
    "mae_best = mean_absolute_error(y_test, y_pred_best)\n",
    "r2_best = r2_score(y_test, y_pred_best)\n",
    "\n",
    "print(f\"\\nEvaluation of the best model:\")\n",
    "print(f\"Mean Squared Error (Best Model): {mse_best}\")\n",
    "print(f\"Root Mean Squared Error (Best Model): {rmse_best}\")\n",
    "print(f\"Mean Absolute Error (Best Model): {mae_best}\")\n",
    "print(f\"R^2 Score (Best Model): {r2_best}\")\n",
    "\n",
    "# Visualization for the best model\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred_best, alpha=0.3)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Actual vs Predicted Salaries (Best Model)')\n",
    "plt.show()\n",
    "\n",
    "# Residuals plot for the best model\n",
    "residuals_best = y_test - y_pred_best\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(residuals_best, kde=True, bins=30)\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Residuals Distribution (Best Model)')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_pred_best, residuals_best, alpha=0.3)\n",
    "plt.axhline(0, color='r', linestyle='--', linewidth=2)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Predicted vs Residuals (Best Model)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3994b49b",
   "metadata": {},
   "source": [
    "# ML PIPELINES AND MODEL DEPLOYMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212bcf96",
   "metadata": {},
   "source": [
    "## Step 1: Define the ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d43f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'Salary Prediction of Data Professions.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop unnecessary columns (e.g., names and dates)\n",
    "df = df.drop(columns=['FIRST NAME', 'LAST NAME', 'DOJ', 'CURRENT DATE'])\n",
    "\n",
    "# Separate features and target variable\n",
    "target = 'SALARY'\n",
    "features = df.drop(columns=[target]).columns\n",
    "\n",
    "# Define the preprocessing steps\n",
    "numeric_features = ['AGE', 'LEAVES USED', 'LEAVES REMAINING', 'RATINGS', 'PAST EXP']\n",
    "categorical_features = ['SEX', 'DESIGNATION', 'UNIT']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean'))\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a pipeline that preprocesses the data and then trains the model\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r2}')\n",
    "\n",
    "# Save the model to disk\n",
    "joblib.dump(model_pipeline, 'salary_prediction_model.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a4e005",
   "metadata": {},
   "source": [
    "## Step 2: Deploy the Model using Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592b2c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the saved model\n",
    "model = joblib.load('salary_prediction_model.pkl')\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    # Get the data from the request\n",
    "    data = request.get_json()\n",
    "    df = pd.DataFrame(data, index=[0])\n",
    "\n",
    "    # Make a prediction\n",
    "    prediction = model.predict(df)\n",
    "\n",
    "    # Return the result as a JSON response\n",
    "    return jsonify({'prediction': prediction[0]})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae35d856",
   "metadata": {},
   "source": [
    "# RECOMMENDATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2de2982",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'Salary Prediction of Data Professions.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop unnecessary columns (e.g., names and dates)\n",
    "df = df.drop(columns=['FIRST NAME', 'LAST NAME', 'DOJ', 'CURRENT DATE'])\n",
    "\n",
    "# Separate features and target variable\n",
    "target = 'SALARY'\n",
    "features = df.drop(columns=[target]).columns\n",
    "\n",
    "# Define the preprocessing steps\n",
    "numeric_features = ['AGE', 'LEAVES USED', 'LEAVES REMAINING', 'RATINGS', 'PAST EXP']\n",
    "categorical_features = ['SEX', 'DESIGNATION', 'UNIT']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean'))\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a pipeline that preprocesses the data and then trains the model\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Save the model to disk\n",
    "joblib.dump(model_pipeline, 'salary_prediction_model.pkl')\n",
    "\n",
    "# Function to generate career path recommendations\n",
    "def recommend_career_path(current_designation):\n",
    "    career_paths = {\n",
    "        'Intern': 'Analyst',\n",
    "        'Analyst': 'Associate',\n",
    "        'Associate': 'Senior Associate',\n",
    "        'Senior Associate': 'Manager',\n",
    "        'Manager': 'Senior Manager',\n",
    "        'Senior Manager': 'Director',\n",
    "        'Director': 'Senior Director',\n",
    "        'Senior Director': 'Vice President',\n",
    "        'Vice President': 'Senior Vice President'\n",
    "    }\n",
    "    \n",
    "    if current_designation in career_paths:\n",
    "        return career_paths[current_designation]\n",
    "    else:\n",
    "        return \"No recommendation available for this designation.\"\n",
    "\n",
    "# Function to recommend skills or experience improvement\n",
    "def recommend_improvement(age, leaves_used, leaves_remaining, ratings, past_exp):\n",
    "    recommendations = []\n",
    "    \n",
    "    if age < 30:\n",
    "        recommendations.append(\"Gain more experience to move to a higher position.\")\n",
    "    \n",
    "    if leaves_used > 20:\n",
    "        recommendations.append(\"Try to reduce the number of leaves used to improve your performance review.\")\n",
    "    \n",
    "    if leaves_remaining < 5:\n",
    "        recommendations.append(\"Save more leaves for potential emergencies.\")\n",
    "    \n",
    "    if ratings < 4:\n",
    "        recommendations.append(\"Focus on improving your ratings by upskilling or taking on challenging projects.\")\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Flask app for serving recommendations\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the saved model\n",
    "model = joblib.load('salary_prediction_model.pkl')\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    # Get the data from the request\n",
    "    data = request.get_json()\n",
    "    df = pd.DataFrame(data, index=[0])\n",
    "\n",
    "    # Make a prediction\n",
    "    prediction = model.predict(df)\n",
    "\n",
    "    # Provide career path recommendation\n",
    "    current_designation = df['DESIGNATION'][0]\n",
    "    next_designation = recommend_career_path(current_designation)\n",
    "    \n",
    "    # Provide improvement recommendations\n",
    "    age = df['AGE'][0]\n",
    "    leaves_used = df['LEAVES USED'][0]\n",
    "    leaves_remaining = df['LEAVES REMAINING'][0]\n",
    "    ratings = df['RATINGS'][0]\n",
    "    past_exp = df['PAST EXP'][0]\n",
    "    improvement_recommendations = recommend_improvement(age, leaves_used, leaves_remaining, ratings, past_exp)\n",
    "    \n",
    "    # Return the result as a JSON response\n",
    "    return jsonify({\n",
    "        'predicted_salary': prediction[0],\n",
    "        'next_designation': next_designation,\n",
    "        'improvement_recommendations': improvement_recommendations\n",
    "    })\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
